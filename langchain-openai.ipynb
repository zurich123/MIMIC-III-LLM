{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20dd47b2-045a-401e-bcc9-389debdbf031",
   "metadata": {},
   "source": [
    "# Langchain - SQL generation on top of postgres DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c7848d-6d98-40d7-ae4a-e12773d874a8",
   "metadata": {},
   "source": [
    "Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e1ca81-e93c-40a1-81f6-b9f02552ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv\n",
    "!pip install langchain\n",
    "!pip install langchain-experimental\n",
    "!pip install 'langchain[openai]'\n",
    "!pip install pandas\n",
    "!pip install boto3>=1.28.57\n",
    "!pip install awscli>=1.29.57\n",
    "!pip install botocore>=1.31.57\n",
    "!pip install psycopg2-binary\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f7965-f450-45ed-8516-b6efb76e4597",
   "metadata": {},
   "source": [
    "**Load environment variables. Make sure to re-run this cell every time you update your .env file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872907c2-e8d3-4a28-bfc5-caeb346db810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3ef145",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b669d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "from langchain.sql_database import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf05a4d-617d-435f-9d93-9428e943af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create a prompt template that has multiple input variables\n",
    "template = PromptTemplate(\n",
    "    input_variables=[\"user_request\"],\n",
    "    template=\"\"\"\n",
    "\n",
    "#Human: Given a user_input question, first create a syntactically correct postgresql query to run, then look at the results of the query and return the answer.\n",
    "\n",
    "CONSTRAINTS:\n",
    "If you have a tool that allows your to see examples of similar queries, use it first to help you create the query.\n",
    "\n",
    "<user_input>\n",
    "{user_input}\n",
    "</user_input>\n",
    "\n",
    "Assistant:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1385453-1121-4f1b-a88f-23fb69e7b72e",
   "metadata": {},
   "source": [
    "# Generate SQL based on Postgres database schemas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a300c791",
   "metadata": {},
   "source": [
    "## Setup database connection\n",
    "If environment variables are missing you didn't create .env file in the folder with Jupyter notebook. Make sure to follow README.md to create the .env file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup database, username and password are taken from your .env file you created earlier.\n",
    "db = SQLDatabase.from_uri(\n",
    "    f\"postgresql+psycopg2://{os.environ.get('DBUSER')}:{os.environ.get('DBPASS')}@{os.environ.get('DBHOST')}:{os.environ.get('DBPORT')}/{os.environ.get('DATABASE')}\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d95421a",
   "metadata": {},
   "source": [
    "Note that context of your database can be quite big to pass to the llm on every request, so I advice to only include tables you need. To see what database information langhcain pulled execute the following: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a8546",
   "metadata": {},
   "source": [
    "To only include tables you would like to work with uncomment and use below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f18a8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = SQLDatabase.from_uri(\n",
    "    f\"postgresql+psycopg2://{os.environ.get('DBUSER')}:{os.environ.get('DBPASS')}@localhost:5432/{os.environ.get('DATABASE')}\",\n",
    "    include_tables=[\n",
    "        \"admissions\",\n",
    "        \"patients\",\n",
    "        \"icustays\"\n",
    "    ],  # LIMIT TO THE TABLES YOU WANT TO USE\n",
    "    schema=\"mimiciii\", #LIMIT TO YOUR SCHEMA\n",
    "    sample_rows_in_table_info=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aa46b6",
   "metadata": {},
   "source": [
    "Make sure you successfully connected to the database and fetched the necessary tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c99417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.table_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c084a",
   "metadata": {},
   "source": [
    "# Open AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff3f11",
   "metadata": {},
   "source": [
    "**Zero-shot example using agent execturor. We are using agent executor here and not a simple SQLDatabaseChain because the agent can answer more complex queries about the database itself and the content.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\") #make sure to select proper model, gpt-4 gives best result but is expensive. gpt-4 or gpt-4-32k\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm=llm,\n",
    "    toolkit=SQLDatabaseToolkit(db=db, llm=llm),\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb8dd4",
   "metadata": {},
   "source": [
    "**Can answer complex questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d941a35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.format(user_input=\"What percentage of admitted patients are married ?\")\n",
    "agent_executor.run(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb1680",
   "metadata": {},
   "source": [
    "**We can also see what tables database contains and describe them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc30234-d0c7-43ff-9677-5098dc4a877e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
